---
title:  "Gradient Penalty"
layout: post
---

<br>

<ul>
    <li>
        General definition of \(K\)-Lipschitz constraint
        <ul>
            <li>
                A function \(f(x)\) is called \(K\)-Lipschitz if there exists a constant \(K\) such that for all points \(x_1, x_2\)
                \[
                    \,\\
                    \| f(x_1) - f(x_2) \| \leq K \| x_1 - x_2 \|               
                    \,\\                
                \]

                if \(K = 1\), we get a 1-Lipschitz function, meaning its rate of change is at most 1. <br>
                if \(K = 2\), we get a 2-Lipschitz function, meaning its rate of change is at most 2.
                if \(K = 3\), we get a 3-Lipschitz function, meaning its rate of change is at most 3.

                Thus, \(K\)-Lipschitz functions allow steeper slopes as \(K\) increases.
            </li>
            <br>
            <li>
                If we divide both sides by \(\| x_1 - x_2 \|\), we get:
                \[
                    \,\\
                    \frac{\| f(x_1) - f(x_2) \|}{\| x_1 - x_2 \|} \leq K
                    \,\\
                \]

                This means that the slope (or gradient) of the function is bounded by \(K\). <br>
                The left hand side is the mean rate of change, which measures how much the function changes between two points. <br>
                Thus the function cannot grow or shrink faster than a line with slope \(K\).
            </li>
        </ul>
    </li>
    <br>
    <li>
        Weight Clipping
        <ul>
            <li>
                For the above expression, let \(f\) be the model's weights \(W\):
                 \[
                    
                        \,\\
                        \frac{\| f(x_1) - f(x_2) \|}{\| x_1 - x_2 \|} = \frac{\| W(x_1) - W(x_2) \|}{\| x_1 - x_2 \|}
                        \,\\
                 \]

                The ratio between the model's output and the input in the above formula is bounded by \(K\). 
                That is, as \(W\) increases, the norm increases, and thus the Lipschitz constant also increases.

                weight clipping이 lipshitz 모든 weight에 대해서 \(| w_{ij} | \leq c \) 로 제한하므로
                따라서  “∣wij∣|w\_{ij}|∣wij​∣가 클수록 operator norm도 커질 수밖에 없으므로, clipping은 간접적으로 Lipschitz 상수를 제한하는 효과를 줌
            </li>
        </ul>
    </li>
    <br>
    <li>
        Gradient Penalty
        <ul>
            <li>
                The gradient penalty is a regularization technique designed to enforce the Lipschitz constraint,
                which plays a role in keeping the discriminator (or critic)'s gradient close to 1. The penalty term is:
                \[
                    \,\\
                    \lambda \cdot \mathbb{E}_{\hat{x} \, \sim \, \mathbb{P}_{\hat{x}}} [\, (\| \nabla_{\hat{x}} \, D(\hat{x}) \|_2 - 1)^2\, ]
                    \,\\
                \]
        
                where:
                <ul class="where-list">
                    <li>
                        \(\hat{x}\) are interpolated samples between real data \(x\) and generated data \(g(z)\), defined as:
                        \[
                            \,\\
                            \hat{x} = \epsilon x + (1 - \epsilon) g(z) \,\, \text{where,} \,\, \epsilon \sim U[0, 1]
                            \,\\
                        \]
                    </li>
                    <li>
                        \(\| \nabla_{\hat{x}} \, D(\hat{x}) \|_2\) is the gradient norm
                    </li>
                    <li>
                        The penalty enforces the Lipschitz constraint by keeping the gradient norm close to 1.
                    </li>
                    <li>
                        \(\lambda\) is a hyperparameter controlling the strength of the penalty.
                    </li>
                </ul>
            </li>
            <br>
<pre><code class="python">
    def compute_gradient_penalty(self, real_data: torch.Tensor, fake_data: torch.Tensor) -> torch.Tensor:
        """Compute the gradient penalty to enforce the Lipschitz constraint.

        Args:
            real_data (torch.Tensor): A batch of real data.
            fake_data (torch.Tensor): A batch of generated data.

        Returns:
            torch.Tensor: The computed gradient penalty.
        """

        batch_size, *_ = real_data.size()

        # epsilon for the voxel interpolation (n, c, d, h, w)
        e = torch.rand((batch_size, 1, 1, 1, 1)).to(self.DEVICE)

        interpolated = (e * real_data + ((1 - e) * fake_data)).requires_grad_(True).to(self.DEVICE)

        # Get the discriminator output for the interpolated data
        d_interpolated = self.discriminator(interpolated)

        # Get the gradients w.r.t. the interpolated data
        gradients, *_ = torch.autograd.grad(
            outputs=d_interpolated,
            inputs=interpolated,
            grad_outputs=torch.ones_like(d_interpolated).to(self.DEVICE),
            create_graph=True,
            retain_graph=True,
            only_inputs=True,
        )

        # Compute the gradient penalty
        gradients = gradients.view(batch_size, -1)
        gradients_norm = torch.sqrt(torch.sum(gradients**2, dim=1) + 1e-12)
        gradient_penalty = self.LAMBDA_1 * ((gradients_norm - 1) ** 2).mean()

        return gradient_penalty
</code></pre>
        </ul>
    </li>
    <!-- <br>
    <li>
        왜 1-Lipschitz 함수여야 하는가?
        <ul>
            <li>
                WGAN에서는 Wasserstein Distance(지구 이동 거리, Earth Mover's Distance)를 최적화해야 하는데, 이를 올바르게 계산하려면 Discriminator가 1-Lipschitz 함수여야 함.
                Wasserstein Distance는 1-Lipschitz 함수를 기반으로 정의되었기 때문에, 이를 어기면 거리 계산이 왜곡됨.
            </li>
        </ul>
    </li> -->
</ul>

<!-- 
    https://chatgpt.com/c/67ad73a4-5490-8011-a686-b50148ed596d
-->




<br><br>