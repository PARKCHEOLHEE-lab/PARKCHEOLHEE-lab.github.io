---
title:  "Intuitions about Transformer"
layout: post
done: false
---

<br>

<ul>
    <li>
        <a href="https://www.youtube.com/watch?v=wjZofJX0v4M&t=640s">But what is a GPT? Visual intro to transformers | Chapter 5, Deep Learning</a>
    </li>
    <li>
        <a href="https://www.youtube.com/watch?v=eMlx5fFNoYc&t=804s">Attention in transformers, visually explained | Chapter 6, Deep Learning</a>
    </li>
    <li>
        <a href="https://www.youtube.com/watch?app=desktop&v=6s69XY025MU#dialog">Attention/Transformer 시각화로 설명</a>
    </li>
    <li>
        <a href="https://www.youtube.com/watch?v=MZYQkL22b38&t=3092s">EP 20. 요즘 나오는 거의 모든 AI 의 기본구조, 트랜스포머 둘러보기</a>
    </li>
    <li>
        <a href="https://lilianweng.github.io/posts/2018-06-24-attention/">Attention? Attention!</a>
    </li>
</ul>

<br><br>