---
title: "Geometric losses"
layout: post
hashtag: "#geometry #conditional-generative-adversairal-networks #deep-learning"
featured: false
comment: true
splitter: 0
thumbnail: /img/geometric-losses-thumbnail.gif
---

<div id="toc"></div>
<h3>Introduction ðŸ’¡</h3>
<div class="article">
    This project was initiated by curiosities about the <code>intersection of geometric data and optimization</code> within the realm of machine learning:

    <ul style="padding-left: 2em;">
        <li class="decimal">Can the geometric properties of data enhance model performance?</li>
        <li class="decimal">Can models converge faster if optimizers have geometric losses?</li>
    </ul>

    <br>

    Based on the above questions, let us observe the concept of geometric loss simply:

    <br><br>

    The concept of geometric loss is grounded in the idea that understanding and leveraging the geometric properties of data is important.
    This understanding and leveraging can significantly enhance model performance, especially in tasks where the spatial arrangement and relationships between data points are crucial.
    
    
    <br><br>
    
    Geometric losses <code>incorporate geometric principles of data into the learning process.</code> 

    <!--break-->

    This approach enables models to recognize and preserve the underlying geometric structures of the dataset.
    
    For instance, in tasks involving images, shapes, or graphs, where the spatial relationships and configurations are essential, geometric losses help in capturing these nuances more effectively than traditional methods.
    


</div><br>

<h3>Problem definition</h3>
<div class="article">

    To experiment with the above questions in the Introduction part, 
    let me define a simple geometric problem. 
    It is to find the <code>largest inscribed rectangle</code> on a given 2d polygon like the following.
    <br><br>

    <figure style="display: flex;">
        <img src="/img/geometric-losses-2.png" width="25%">
        <img src="/img/geometric-losses-3.png" width="25%">
        <img src="/img/geometric-losses-1.png" width="25%">
    </figure>
    <figcaption style="text-align: center; margin-top: 1em">
        <a href="https://community.esri.com/t5/spatial-data-science-questions/how-to-find-the-maximum-rectangle-contained-within/td-p/408977">The largest inscribed rectangle</a>    
    </figcaption>

    <br><br>

    After defining a geometric problem, I defined the algorithm for finding <a href="https://github.com/PARKCHEOLHEE-lab/toytorch/blob/766853852c332c66decf3478eace9fd034c0602d/lirGAN/data/largest_inscribed_rectangle.py#L12-L133">LIR</a>.
    In this algorithm, a given polygon is represented as a <code>binary grid</code> of 1s and 0s.
    1 is represented as a solid part and 0 is represented as a void part. 
    The following representation of a binary grid-shaped polygon has 100 x 100 grid size. If the size is higher, it can be represented more precisely.

    <br><br>

    <figure>
        <img src="../img/geometric-losses-4.png" style="width: 80%; display: block; margin-left: auto; margin-right: auto;">
        <figcaption style="text-align: center; margin-top: 1em">
            Representation of a geometry<br>
            From the left, Vector-shaped polygon Â· Binary grid-shaped polygon
        </figcaption>
    </figure>


</div><br>

<h3>Data preparation</h3>
<div class="article">

    We have set up a problem and a way to represent geometric data to experiment with the problem in the above section. 
    In this part, we create a dataset to train a generator that estimates the <code>LIR</code> given an input polygon.

    <br><br>

    First of all, I'm going to define the function for creating a polygon with random coordinates called <code>_get_random_coordinates</code> as follows:
    
<pre><code class="python">
    def _get_random_coordinates(
        self, vertices_count_min: int, vertices_count_max: int, scale_factor: float = 1.0
    ) -> np.ndarray:
        """Generate non-intersected polygon randomly

        Args:
            vertices_count_min (int): random vertices count minimum value
            vertices_count_max (int): random vertices count maximum value
            scale_factor (float, optional): constant to scale. Defaults to 1.0.

        Returns:
            np.ndarray: random coordinates
        """

        vertices_count = np.random.randint(vertices_count_min, vertices_count_max)
        vertices = np.random.rand(vertices_count, 2)
        vertices_centroid = np.mean(vertices, axis=0)

        coordinates = sorted(vertices, key=lambda p, c=vertices_centroid: np.arctan2(p[1] - c[1], p[0] - c[0]))

        coordinates = np.array(coordinates)
        coordinates[:, 0] *= scale_factor
        coordinates[:, 1] *= scale_factor

        return coordinates
</pre></code><br><br>

    This algorithm sorts polygon vertices by angle from the center to each vertex so that they do not intersect.
    The whole process of creating a random polygon is as follows and you can see the code in this <a href="https://github.com/PARKCHEOLHEE-lab/toytorch/blob/766853852c332c66decf3478eace9fd034c0602d/lirGAN/data/data_creator.py#L45-L69">link</a>.
    <br><br>

    <figure>
        <img src="../img/geometric-losses-5.png" style="width: 70%; display: block; margin-left: auto; margin-right: auto;">
        <figcaption style="text-align: center; margin-top: 1em">
            The process of creating a random polygon
        </figcaption>
    </figure>

    <br><br>

    After creating each random polygon, it needs to <a href="https://github.com/PARKCHEOLHEE-lab/toytorch/blob/766853852c332c66decf3478eace9fd034c0602d/lirGAN/data/data_creator.py#L71-L98">resize</a> as much as the grid size(I set 256x256).
    We then need to <a href="https://github.com/PARKCHEOLHEE-lab/toytorch/blob/766853852c332c66decf3478eace9fd034c0602d/lirGAN/data/utils.py#L59-L74">convert</a> these <code>vector-shaped polygons to binary grid-shaped polygons</code> consisting of 1s and 0s. It's easy with OpenCV.
    Through this process, <a href="https://github.com/PARKCHEOLHEE-lab/toytorch/tree/main/lirGAN/data/binpy">5000 datasets</a> were created as shown in the figure below. If you need more data sets, you can get them easily.

    <br><br>

    <figure>
        <img src="../img/geometric-losses-6.png" style="width: 80%; display: block; margin-left: auto; margin-right: auto;">
        <img src="../img/geometric-losses-8.png" style="width: 80%; display: block; margin-left: auto; margin-right: auto;">
        <img src="../img/geometric-losses-9.png" style="width: 80%; display: block; margin-left: auto; margin-right: auto;">
        <img src="../img/geometric-losses-10.png" style="width: 80%; display: block; margin-left: auto; margin-right: auto;">
        <img src="../img/geometric-losses-11.png" style="width: 80%; display: block; margin-left: auto; margin-right: auto;">
        <img src="../img/geometric-losses-12.png" style="width: 80%; display: block; margin-left: auto; margin-right: auto;">
        <img src="../img/geometric-losses-13.png" style="width: 80%; display: block; margin-left: auto; margin-right: auto;">
        <img src="../img/geometric-losses-14.png" style="width: 80%; display: block; margin-left: auto; margin-right: auto;">
        <img src="../img/geometric-losses-15.png" style="width: 80%; display: block; margin-left: auto; margin-right: auto;">
        <img src="../img/geometric-losses-16.png" style="width: 80%; display: block; margin-left: auto; margin-right: auto;">
        <figcaption style="text-align: center; margin-top: 1em">
            The process of creating a random polygon
        </figcaption>
    </figure>


</div><br>

<h3>Building models and loss functions</h3>
<div class="article">

    In this section, we will build a model based on DCGANs architecture for 256x256 data and implement a geometric loss function.
    Additionally, since the generator model uses a given polygon as one of its inputs(with noise vector), the <code>conditional GANs</code> structure must be taken into account. 

    <br><br>

    The paper for <a href="https://arxiv.org/pdf/1411.1784.pdf">Conditional Generative Adversarial Nets</a> says:
    <br>
    <b>"</b> Generative adversarial nets can be extended to a conditional model if both the generator and discriminator are conditioned on some <code>extra information y</code>. 
    y could be any kind of auxiliary information, such as class labels or data from other modalities. We can perform the conditioning by feeding y into the both the discriminator and generator as additional input layer. <b>"</b>
    

    <figure>
        <img src="../img/geometric-losses-7.png" style="width: 80%; display: block; margin-left: auto; margin-right: auto;">
        <figcaption style="text-align: center; margin-top: 1em">
            Conditional adversarial net
        </figcaption>
    </figure><br>

    In the LIR problem contexts we defined, <code>extra information y</code> corresponds to an input polygon.
    The following <a href="https://github.com/PARKCHEOLHEE-lab/toytorch/blob/766853852c332c66decf3478eace9fd034c0602d/lirGAN/model.py#L235-L244">forward</a> propagation method takes two inputs: noise and input polygon.
    The <code>input_polygon</code> is first flattened and then this reshaped tensor is converted to feature space by passing through fully connected layers.

    <br><br>

    The output(128) of the linear transformation is concatenated with the noise(128) tensor. 
    This concatenation(256) allows the model to use both the random noise and the information from the <code>input_polygon</code> to generate the output.
    
<pre><code class="python">
    class LirGenerator(nn.Module, ModelConfig):

        ( ... )

        def forward(self, noise, input_polygon):
            fc = self.linear(input_polygon.reshape(input_polygon.shape[0], -1))
            x = torch.cat([noise, fc], dim=1)
            x = x.reshape(x.shape[0], 256, 1, 1)
            x = self.main(x)

            if self.use_tanh:
                return nn.Tanh()(x)

            return nn.Sigmoid()(x)
</pre></code><br><br>

    Similarly, the <a href="https://github.com/PARKCHEOLHEE-lab/toytorch/blob/766853852c332c66decf3478eace9fd034c0602d/lirGAN/model.py#L247C10-L272">discriminator</a> takes the input polygon as additional input. 
    In the forward propagation method of the discriminator, the <code>rectangle</code> and <code>input_polygon</code> have the same shape as the tensor. 
    So we just need to connect them and then pass them to the main layer.

    <pre><code class="python">
        class LirDiscriminator(nn.Module, ModelConfig):
            def __init__(self):
                super().__init__()
        
                self.main = nn.Sequential(
                    nn.Conv2d(2, 64, kernel_size=4, stride=2, padding=1, bias=False),
                    nn.LeakyReLU(0.2, inplace=True),
                    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),
                    nn.BatchNorm2d(128),
                    nn.LeakyReLU(0.2, inplace=True),
                    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),
                    nn.BatchNorm2d(256),
                    nn.LeakyReLU(0.2, inplace=True),
                    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),
                    nn.BatchNorm2d(512),
                    nn.LeakyReLU(0.2, inplace=True),
                    nn.Conv2d(512, 1, kernel_size=4, stride=2, padding=0, bias=False),
                    nn.AdaptiveAvgPool2d(1),
                    nn.Sigmoid(),
                )
        
                self.to(self.DEVICE)

            def forward(self, rectangle, input_polygon):
                x = torch.cat([rectangle, input_polygon], dim=1)
                return self.main(x).view(-1, 1).squeeze(1)
    </pre></code><br><br>

    Next, let us define the <code>LirGeometricLoss</code> class that wil be used to train the <code>LirGenerator</code> defined above.
    The losses are consisting of:
    
    <ul style="padding-left: 2em;">
        <li class="decimal">BCE loss is a standard loss function used for binary classification tasks </li>
        <li class="decimal"><a href="https://deep-learning-study.tistory.com/634">DIoU</a> loss, or Distance Intersection over Union Loss, is a metric used to evaluate the similarity between two boxes</li>
        <li class="decimal">Feasibility loss</li>
        <li class="decimal">Connectivity loss</li>
    </ul>
    
</div><br>

<h3>Training and evaluating</h3>
<div class="article">
    
    <figure style="display: flex;">
        <img src="/img/without-geometric-loss-polygons.gif" width="48.5%">
        <img src="/img/with-geometric-loss-polygons.gif" width="48.5%">
    </figure>
    
    <figure style="display: flex;">
        <img src="/img/without-geometric-loss-graphs.gif" width="48.5%">
        <img src="/img/with-geometric-loss-graphs.gif" width="48.5%">
    </figure>

</div><br>

<h3>Potential improvements</h3>
<div class="article">

</div><br>

<h3>References</h3>
<div class="article">

    <ul>
        <li><a href="https://towardsdatascience.com/a-brief-introduction-to-geometric-deep-learning-dae114923ddb">https://towardsdatascience.com/a-brief-introduction-to-geometric-deep-learning-dae114923ddb</a></li>
        <li><a href="https://deep-learning-study.tistory.com/634">https://deep-learning-study.tistory.com/634</a></li>
        <li><a href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html">https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html</a></li>
        <li><a href="https://www.kaggle.com/code/arturlacerda/pytorch-conditional-gan">https://www.kaggle.com/code/arturlacerda/pytorch-conditional-gan</a></li>
        <li><a href="https://arxiv.org/pdf/1411.1784.pdf">https://arxiv.org/pdf/1411.1784.pdf</a></li>
        <li><a href="https://deep-learning-study.tistory.com/634">https://deep-learning-study.tistory.com/634</a></li>
    </ul>
    
</div><br><br>