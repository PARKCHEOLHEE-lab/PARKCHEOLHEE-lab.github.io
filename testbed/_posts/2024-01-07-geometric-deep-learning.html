---
title: "Shape-conditional GANs"
layout: post
hashtag: "#geometry #conditional-generative-adversairal-networks #deep-learning"
featured: false
comment: true
splitter: 0
thumbnail: /img/polygons-thumbnail-2.gif
---

<div id="toc"></div>

<h3>What is Conditional Generative Adversarial Networks ❓</h3>
<div class="article">

    <code>Conditional Generative Adversarial Networks</code> (cGANs) is an extension of the original Generative Adversarial Networks.
    cGANs take the concept of conventional GANs further by feeding additional information into both the generator and discriminator, allowing the generation of data that is more specific and controlled.

    This information acts as a directive or constraint for the generator on what type of data to produce. 

    <br><br>
    
    The paper for <a href="https://arxiv.org/pdf/1411.1784.pdf">Conditional Generative Adversarial Nets</a> says:
    <br>
    <b>"</b> Generative adversarial nets can be extended to a conditional model if both the generator and discriminator are conditioned on some <code>extra information y.</code> 
    y could be any kind of auxiliary information, such as class labels or data from other modalities. We can perform the conditioning by feeding y into the both the discriminator and generator as additional input layer. <b>"</b>
    
    <!--break-->

    <figure>
        <img src="../img/geometric-losses-7.png" style="width: 80%; display: block; margin-left: auto; margin-right: auto;">
        <figcaption style="text-align: center; margin-top: 1em">
            Conditional adversarial net
        </figcaption>
    </figure><br>
    
    Since I am interested in handling geometry and generative design, I wanted to combine my interests with cGAN to solve a simple problem and understand these concepts.

</div><br>

<h3>Problem definition</h3>
<div class="article">

    To experiment with the above, 
    let me define a simple geometric problem. 
    It is to find the <code>largest inscribed rectangle</code> on a given 2d polygon like the following.
    <br><br>

    <figure style="display: flex;">
        <img src="/img/geometric-losses-2.png" width="25%">
        <img src="/img/geometric-losses-3.png" width="25%">
        <img src="/img/geometric-losses-1.png" width="25%">
    </figure>
    <figcaption style="text-align: center; margin-top: 1em">
        <a href="https://community.esri.com/t5/spatial-data-science-questions/how-to-find-the-maximum-rectangle-contained-within/td-p/408977">The largest inscribed rectangle</a>    
    </figcaption>

    <br><br>

    After setting a geometric problem, I defined the algorithm for finding <a href="https://github.com/PARKCHEOLHEE-lab/toytorch/blob/766853852c332c66decf3478eace9fd034c0602d/lirGAN/data/largest_inscribed_rectangle.py#L12-L133">LIR</a>.
    In this algorithm, a given polygon is represented as a <code>binary grid</code> of 1s and 0s.
    1 is represented as a solid part and 0 is represented as a void part. 
    The following representation of a binary grid-shaped polygon has 100 x 100 grid size. If the size is higher, it can be represented more precisely.

    <br><br>

    <figure>
        <img src="../img/geometric-losses-4.png" style="width: 80%; display: block; margin-left: auto; margin-right: auto;">
        <figcaption style="text-align: center; margin-top: 1em">
            Representation of a geometry<br>
            From the left, Vector-shaped polygon · Binary grid-shaped polygon
        </figcaption>
    </figure>


</div><br>

<h3>Data preparation</h3>
<div class="article">

    We have set up a problem and a way to represent geometric data to experiment with the problem in the above section. 
    In this part, we create a dataset to train a generator that estimates the <code>LIR</code> given an input polygon.

    <br><br>

    First of all, I'm going to define the function for creating a polygon with random coordinates called <code>_get_random_coordinates</code> as follows:
    
<pre><code class="python">
    def _get_random_coordinates(
        self, vertices_count_min: int, vertices_count_max: int, scale_factor: float = 1.0
    ) -> np.ndarray:
        """Generate non-intersected polygon randomly

        Args:
            vertices_count_min (int): random vertices count minimum value
            vertices_count_max (int): random vertices count maximum value
            scale_factor (float, optional): constant to scale. Defaults to 1.0.

        Returns:
            np.ndarray: random coordinates
        """

        vertices_count = np.random.randint(vertices_count_min, vertices_count_max)
        vertices = np.random.rand(vertices_count, 2)
        vertices_centroid = np.mean(vertices, axis=0)

        coordinates = sorted(vertices, key=lambda p, c=vertices_centroid: np.arctan2(p[1] - c[1], p[0] - c[0]))

        coordinates = np.array(coordinates)
        coordinates[:, 0] *= scale_factor
        coordinates[:, 1] *= scale_factor

        return coordinates
</pre></code><br><br>

    This algorithm sorts polygon vertices by angle from the center to each vertex so that they do not intersect.
    The whole process of creating a random polygon is as follows and you can see the code in this <a href="https://github.com/PARKCHEOLHEE-lab/toytorch/blob/766853852c332c66decf3478eace9fd034c0602d/lirGAN/data/data_creator.py#L45-L69">link</a>.
    <br><br>

    <figure>
        <img src="../img/geometric-losses-5.png" style="width: 70%; display: block; margin-left: auto; margin-right: auto;">
        <figcaption style="text-align: center; margin-top: 1em">
            The process of creating a random polygon
        </figcaption>
    </figure>

    <br><br>

    After creating each random polygon, it needs to <a href="https://github.com/PARKCHEOLHEE-lab/toytorch/blob/766853852c332c66decf3478eace9fd034c0602d/lirGAN/data/data_creator.py#L71-L98">resize</a> as much as the grid size(I set 256x256).
    We then need to <a href="https://github.com/PARKCHEOLHEE-lab/toytorch/blob/766853852c332c66decf3478eace9fd034c0602d/lirGAN/data/utils.py#L59-L74">convert</a> these <code>vector-shaped polygons to binary grid-shaped polygons</code> consisting of 1s and 0s. It's easy with OpenCV.
    Through this process, <a href="https://github.com/PARKCHEOLHEE-lab/toytorch/tree/main/lirGAN/data/binpy">5000 datasets</a> were created as shown in the figure below. If you need more data sets, you can get them easily.

    <br><br>

    <figure>
        <img src="../img/geometric-losses-6.png" style="width: 100%; display: block; margin-left: auto; margin-right: auto;">
        <img src="../img/geometric-losses-8.png" style="width: 100%; display: block; margin-left: auto; margin-right: auto;">
        <img src="../img/geometric-losses-9.png" style="width: 100%; display: block; margin-left: auto; margin-right: auto;">
        <img src="../img/geometric-losses-10.png" style="width: 100%; display: block; margin-left: auto; margin-right: auto;">
        <img src="../img/geometric-losses-11.png" style="width: 100%; display: block; margin-left: auto; margin-right: auto;">
        <img src="../img/geometric-losses-12.png" style="width: 100%; display: block; margin-left: auto; margin-right: auto;">
        <img src="../img/geometric-losses-13.png" style="width: 100%; display: block; margin-left: auto; margin-right: auto;">
        <img src="../img/geometric-losses-14.png" style="width: 100%; display: block; margin-left: auto; margin-right: auto;">
        <img src="../img/geometric-losses-15.png" style="width: 100%; display: block; margin-left: auto; margin-right: auto;">
        <img src="../img/geometric-losses-16.png" style="width: 100%; display: block; margin-left: auto; margin-right: auto;">
        <figcaption style="text-align: center; margin-top: 1em">
            The process of creating a random polygon
        </figcaption>
    </figure>


</div><br>

<h3>Building models and loss functions</h3>
<div class="article">

    In this section, we will build a model based on DCGANs architecture for 256x256 data and implement a geometric loss function.

    <br><br>

    In the LIR problem contexts we defined, <code>extra information y</code> corresponds to an input polygon.
    The following <a href="https://github.com/PARKCHEOLHEE-lab/toytorch/blob/766853852c332c66decf3478eace9fd034c0602d/lirGAN/model.py#L235-L244">forward</a> propagation method takes two inputs: noise and input polygon.
    The <code>input_polygon</code> is first flattened and then this reshaped tensor is converted to feature space by passing through fully connected layers.

    <br><br>

    The output(128) of the linear transformation is concatenated with the noise(128) tensor. 
    This concatenation(256) allows the model to use both the random noise and the information from the <code>input_polygon</code> to generate the output.
    
<pre><code class="python">
    class LirGenerator(nn.Module, ModelConfig):

        ( ... )

        def forward(self, noise, input_polygon):
            fc = self.linear(input_polygon.reshape(input_polygon.shape[0], -1))
            x = torch.cat([noise, fc], dim=1)
            x = x.reshape(x.shape[0], 256, 1, 1)
            x = self.main(x)

            if self.use_tanh:
                return nn.Tanh()(x)

            return nn.Sigmoid()(x)
</pre></code><br><br>

    Similarly, the <a href="https://github.com/PARKCHEOLHEE-lab/toytorch/blob/766853852c332c66decf3478eace9fd034c0602d/lirGAN/model.py#L247C10-L272">discriminator</a> takes the input polygon as additional input. 
    In the forward propagation method of the discriminator, the <code>rectangle</code> and <code>input_polygon</code> have the same shape as the tensor. 
    So we just need to connect them and then pass them to the main layer.

    <pre><code class="python">
        class LirDiscriminator(nn.Module, ModelConfig):
            def __init__(self):
                super().__init__()
        
                self.main = nn.Sequential(
                    nn.Conv2d(2, 64, kernel_size=4, stride=2, padding=1, bias=False),
                    nn.LeakyReLU(0.2, inplace=True),
                    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),
                    nn.BatchNorm2d(128),
                    nn.LeakyReLU(0.2, inplace=True),
                    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),
                    nn.BatchNorm2d(256),
                    nn.LeakyReLU(0.2, inplace=True),
                    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),
                    nn.BatchNorm2d(512),
                    nn.LeakyReLU(0.2, inplace=True),
                    nn.Conv2d(512, 1, kernel_size=4, stride=2, padding=0, bias=False),
                    nn.AdaptiveAvgPool2d(1),
                    nn.Sigmoid(),
                )
        
                self.to(self.DEVICE)

            def forward(self, rectangle, input_polygon):
                x = torch.cat([rectangle, input_polygon], dim=1)
                return self.main(x).view(-1, 1).squeeze(1)
    </pre></code><br><br>

    Next, let us define the <a href="https://github.com/PARKCHEOLHEE-lab/toytorch/blob/766853852c332c66decf3478eace9fd034c0602d/lirGAN/model.py#L55C7-L168">additional loss functions</a> that compute the geometric features of generated data. I think these losses will help train the generator stably.

    The losses consist of:
    
    <ul style="padding-left: 2em;">
        <li class="decimal"><u>BCE loss</u> is a standard loss function used for binary classification tasks(conventional GANs do not use any loss other than the adversarial loss, but without these losses when training the generator, the model did not create rectangles) </li>
        <li class="decimal"><u><a href="https://deep-learning-study.tistory.com/634">DIoU</a> loss</u>, or Distance Intersection over Union Loss, is a metric used to evaluate the similarity between two boxes</li>
        <li class="decimal"><u>Feasibility loss</u> measures how well the generated rectangle fits within the input polygon(and target rectangle) without overextending beyond its boundaries or underfitting within them</li>
        <li class="decimal"><u>Connectivity loss</u> checks whether the generated rectangle is a single piece using the labeling function</li>
    </ul>
    
</div><br>

<h3>Training and evaluating</h3>
<div class="article">

    <figure>
        <img src="../img/with-geometric-loss-polygons-2000.gif" style="width: 80%; display: block; margin-left: auto; margin-right: auto;">
        <img src="../img/without-geometric-loss-polygons-2000.gif" style="width: 80%; display: block; margin-left: auto; margin-right: auto;">
        <figcaption style="text-align: center; margin-top: 1em">
            The process of creating a random polygon
        </figcaption>
    </figure>
    
    <!-- <figure style="display: flex;">
        <img src="/img/without-geometric-loss-polygons.gif" width="48.5%">
        <img src="/img/with-geometric-loss-polygons.gif" width="48.5%">
    </figure>
    
    <figure style="display: flex;">
        <img src="/img/without-geometric-loss-graphs.gif" width="48.5%">
        <img src="/img/with-geometric-loss-graphs.gif" width="48.5%">
    </figure> -->

</div><br>

<h3>References</h3>
<div class="article">

    <ul>
        <li><a href="https://towardsdatascience.com/a-brief-introduction-to-geometric-deep-learning-dae114923ddb">https://towardsdatascience.com/a-brief-introduction-to-geometric-deep-learning-dae114923ddb</a></li>
        <li><a href="https://deep-learning-study.tistory.com/634">https://deep-learning-study.tistory.com/634</a></li>
        <li><a href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html">https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html</a></li>
        <li><a href="https://www.kaggle.com/code/arturlacerda/pytorch-conditional-gan">https://www.kaggle.com/code/arturlacerda/pytorch-conditional-gan</a></li>
        <li><a href="https://arxiv.org/pdf/1411.1784.pdf">https://arxiv.org/pdf/1411.1784.pdf</a></li>
        <li><a href="https://deep-learning-study.tistory.com/634">https://deep-learning-study.tistory.com/634</a></li>
    </ul>
    
</div><br><br>